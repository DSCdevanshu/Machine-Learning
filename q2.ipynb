{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.backends.registry'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\matplotlib\\__init__.py:161\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrcsetup\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\matplotlib\\rcsetup.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\matplotlib\\backends\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# NOTE: plt.switch_backend() (called at import time) will add a \"backend\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# attribute here for backcompat.\u001b[39;00m\n\u001b[32m      5\u001b[39m _QT_FORCE_QT5_BINDING = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib.backends.registry'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('AB_NYC_2019.xlsx')\n",
    "\n",
    "# Display first few rows\n",
    "print('First 5 rows of the dataset:')\n",
    "print(df.head())\n",
    "\n",
    "# Check dataset info\n",
    "print('\\nDataset Info:')\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print('\\nMissing Values:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "print('\\nNumber of Duplicate Rows:')\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Handle Missing, Duplicate, and Inconsistent Values\n",
    "\n",
    "We'll address:\n",
    "- **Missing Values**: Columns like `name`, `host_name`, `last_review`, and `reviews_per_month` may have missing values. We'll decide whether to fill or drop them based on relevance.\n",
    "- **Duplicates**: Remove any duplicate rows if present.\n",
    "- **Inconsistent Values**: Check for outliers or invalid entries (e.g., `price` <= 0, negative `minimum_nights`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# Drop 'name' and 'host_name' as they are not critical for analysis\n",
    "df = df.drop(['name', 'host_name'], axis=1)\n",
    "\n",
    "# Fill missing 'last_review' with a placeholder date (e.g., dataset start)\n",
    "df['last_review'] = df['last_review'].fillna('1900-01-01')\n",
    "\n",
    "# Fill missing 'reviews_per_month' with 0 (no reviews)\n",
    "df['reviews_per_month'] = df['reviews_per_month'].fillna(0)\n",
    "\n",
    "# Verify missing values are handled\n",
    "print('Missing Values After Handling:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Remove duplicates if any\n",
    "df = df.drop_duplicates()\n",
    "print('\\nNumber of Duplicate Rows After Removal:')\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Check for inconsistent values\n",
    "# Remove rows with price <= 0\n",
    "df = df[df['price'] > 0]\n",
    "\n",
    "# Remove rows with negative or unrealistic minimum_nights (e.g., > 365)\n",
    "df = df[(df['minimum_nights'] > 0) & (df['minimum_nights'] <= 365)]\n",
    "\n",
    "# Check for outliers in price using IQR\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[(df['price'] >= Q1 - 1.5 * IQR) & (df['price'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "print('\\nDataset Shape After Cleaning:')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Convert Categorical Variables\n",
    "\n",
    "We'll encode categorical variables (`neighbourhood_group`, `neighbourhood`, `room_type`) using LabelEncoder for simplicity. For high-cardinality columns like `neighbourhood`, we could use target encoding in a modeling context, but LabelEncoder suffices for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode 'neighbourhood_group'\n",
    "df['neighbourhood_group'] = le.fit_transform(df['neighbourhood_group'])\n",
    "print('\\nUnique neighbourhood_group values:', df['neighbourhood_group'].unique())\n",
    "\n",
    "# Encode 'neighbourhood'\n",
    "df['neighbourhood'] = le.fit_transform(df['neighbourhood'])\n",
    "print('Unique neighbourhood values:', df['neighbourhood'].unique())\n",
    "\n",
    "# Encode 'room_type'\n",
    "df['room_type'] = le.fit_transform(df['room_type'])\n",
    "print('Unique room_type values:', df['room_type'].unique())\n",
    "\n",
    "# Verify encoding\n",
    "print('\\nDataset Head After Encoding:')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Handle Skewed Distributions\n",
    "\n",
    "The `price` column is often right-skewed in Airbnb datasets. We'll apply a log-transformation to normalize it and visualize the distribution before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original price distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['price'], kde=True, color='blue')\n",
    "plt.title('Price Distribution (Original)')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Apply log-transformation to price\n",
    "df['price_log'] = np.log1p(df['price'])  # log1p handles zero values\n",
    "\n",
    "# Visualize log-transformed price distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['price_log'], kde=True, color='green')\n",
    "plt.title('Price Distribution (Log-Transformed)')\n",
    "plt.xlabel('Log(Price)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Drop original price column\n",
    "df = df.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Drop Irrelevant or Highly Correlated Features\n",
    "\n",
    "We'll:\n",
    "- **Drop Irrelevant Features**: Columns like `id`, `host_id`, and `last_review` are not useful for most analyses.\n",
    "- **Check for High Correlation**: Use a correlation matrix to identify and drop highly correlated features (e.g., correlation > 0.8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "df = df.drop(['id', 'host_id', 'last_review'], axis=1)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated features (> 0.8)\n",
    "high_corr = [(col1, col2) for col1 in corr_matrix for col2 in corr_matrix if (corr_matrix.loc[col1, col2] > 0.8) and (col1 != col2)]\n",
    "print('\\nHighly Correlated Features (> 0.8):')\n",
    "print(high_corr if high_corr else 'None')\n",
    "\n",
    "# No highly correlated features in this dataset, so no additional drops needed\n",
    "\n",
    "# Final dataset info\n",
    "print('\\nFinal Dataset Info:')\n",
    "print(df.info())\n",
    "print('\\nFinal Dataset Head:')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- **Missing Values**: Dropped `name` and `host_name` as non-essential; filled `last_review` and `reviews_per_month` appropriately.\n",
    "- **Duplicates and Inconsistencies**: Removed duplicates and invalid entries (e.g., `price` <= 0, unrealistic `minimum_nights`).\n",
    "- **Categorical Variables**: Encoded `neighbourhood_group`, `neighbourhood`, and `room_type` using LabelEncoder.\n",
    "- **Skewed Distributions**: Log-transformed `price` to normalize its distribution.\n",
    "- **Feature Selection**: Dropped irrelevant columns (`id`, `host_id`, `last_review`) and confirmed no highly correlated features.\n",
    "\n",
    "The preprocessed dataset is now clean and ready for further analysis or modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
